\documentclass[12pt]{article}
\usepackage[12pt]{moresize}
\usepackage[margin=1in]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{multirow} %Combining rows in tables
\usepackage{diagbox}  %Table box split in twain

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{alltt}

\usepackage{multicol}

\usepackage{amssymb} %\checkmark symbol

%\usepackage{hyperref}
%\usepackage[latin1]{inputenc}
%\usepackage{listings}
%\usepackage{scrextend}
%\usepackage{changepage} %Adjustwidth

 

\title{Stat 330\\Homework 6}
\author{Sean Gordon}
\date{March 6, 2020}

\begin{document}
\maketitle


\noindent\hrulefill \\[-.8em]


\noindent 1)\\
\indent (a) 
\begin{tabular}{c|ccc|c}
 \hline &&&&\\[-1em]
 \diagbox{X}{Y} & 0 & 1 & 2 & $p_x(x)$ \\
 \hline &&&&\\[-1em]
0 & 0.3 & 0.1 & 0.1 & 0.5 \\
1 & 0.2 & 0.1 & 0 & 0.3 \\
2 & 0.1 & 0.1 & 0 & 0.2 \\
\hline &&&&\\[-1em]
$p_y(y)$ & 0.6 & 0.3 & 0.1 & 1
\end{tabular}\\\\

\indent (b) 
E(X) = (0)(0.5) + (1)(0.3) + (2)(0.2) = 0.7 \\
\indent\indent E(Y) = (0)(0.6) + (1)(0.3) + (2)(0.1) = 0.5 \\

\indent\indent E(X$^2$) = (0)$^2$(0.5) + (1)$^2$(0.3) + (2)$^2$(0.2) = 1.1 \\
\indent\indent E(Y$^2$) = (0)$^2$(0.5) + (1)$^2$(0.3) + (2)$^2$(0.2) = 0.7 \\

\indent\indent Var(X) = E(X$^2$) - $|$E(X)$|^2$ = 1.1 - 0.7$^2$ = 0.61\\
\indent\indent Var(Y) = E(Y$^2$) - $|$E(Y)$|^2$ = 0.7 - 0.5$^2$ = 0.45\\


\indent (c) 
E(XY) = (0)(0)(0.3) + (1)(0)(0.1) + (2)(0)(0.1) + \\
\indent\indent \indent \indent \indent (0)(1)(0.2) + (1)(1)(0.1) + (2)(1)(0) + \\
\indent\indent \indent \indent \indent (0)(2)(0.1) + (1)(2)(0.1) + (2)(2)(0) = 0.3\\

\indent \indent Cov(X, Y) = E(XY) - E(X)E(Y) = 0.3 - (0.7)(0.5) = -0.05\\

\indent \indent Corr(X, Y) = {\Large $\frac{Cov(X, Y)}{\sqrt{Var(X)*Var(Y)}}$} = {\Large $\frac{-0.05}{\sqrt{0.61 * 0.45}}$} = -0.095\\\\

\indent (d) Covariance != 0, and $p_{x, y}(1, 0)$ != $p_{x}(1)$ * $p_{y}(0)$. \\
\indent \indent Therefore the two days are not independent.\\


\noindent \hrulefill 


\noindent 2)\\
\indent (a) P(X=Y) = $p_{x, y}(0, 0)$ + $p_{x, y}(1, 1)$ + $p_{x, y}(2, 2)$ = 0.3 + 0.1 + 0 = 0.4\\

\indent (b) P(X$<$Y) = $p_{x, y}(0, 1)$ + $p_{x, y}(0, 2)$ + $p_{x, y}(1, 2)$ = 0.1 + 0.1 + 0 = 0.2\\

\indent (c) P(X$>$Y) = $p_{x, y}(1, 0)$ + $p_{x, y}(2, 0)$ + $p_{x, y}(2, 1)$ = 0.2 + 0.1 + 0.1 = 0.4\\

\indent (d) $p_{x, y}(0, 0)$ = 0.3\\

\indent (e) $p_{x, y}(1, 2)$ = 0\\


\noindent \hrulefill \\


\noindent 3)\\
\indent (a, b) 
\begin{tabular}{c|cccc|c}
 \hline &&&&&\\[-1em]
 \diagbox{X}{Y} & 0 & 1 & 2 & 3 & $p_x(x)$ \\
 \hline &&&&&\\[-1em]
0 & 0.125 & 0.25  & 0.125 & 0 & .5 \\
1 & 0        & 0.125 & 0.25  & 0.125 & .5 \\
\hline &&&&&\\[-1em]
$p_y(y)$ & 0.125 & 0.375 & 0.375 & 0.125 & 1
\end{tabular}\\\\

\indent (c) P(Y=1 $|$ X=1) = {\Large $\frac{P(X=1, Y=1)}{P(X=1)}$} $\Rightarrow$ {\Large $\frac{0.125}{0.5}$} = 0.25\\


\noindent \hrulefill \\


\noindent 4)\\
\indent (a) 
\begin{tabular}{c|ccc|c}
 \hline &&&&\\[-1em]
 \diagbox{X}{Y} & 2 & 3 & 4 & $p_x(x)$ \\
 \hline &&&&\\[-1em]
1 & 0.083 & 0.167 & 0 & 0.25 \\
2 & 0.167 & 0 & 0.333 & 0.5 \\
3 & 0.083 & 0.167 & 0 & 0.25\\
\hline &&&&\\[-1em]
$p_y(y)$ & 0.333 & 0.333 & 0.333 & 1
\end{tabular}\\\\

\indent (b) Two variables are independent if, for all values of X and Y:\\
\indent \indent P(x $|$ y) = P(x)\\
\indent \indent P(x $\cap$ y) = P(x)*P(y)\\
\indent \indent The variables are dependent, as P(x $\cap$ y) for (2, 3) = 0, but P(X=2)*P(Y=3) = .167\\
\indent \indent This violates the second rule of independence.\\\\

\indent (c) 
\begin{tabular}{c|ccc|c}
 \hline &&&&\\[-1em]
 \diagbox{A}{B} & 2 & 3 & 4 & $p_x(x)$ \\
 \hline &&&&\\[-1em]
1 & 0.083 & 0.083 & 0.083 & 0.25 \\
2 & 0.167 & 0.167 & 0.167 & 0.5 \\
3 & 0.083 & 0.083 & 0.083 & 0.25\\
\hline &&&&\\[-1em]
$p_y(y)$ & 0.333 & 0.333 & 0.333 & 1
\end{tabular}\\


\noindent \hrulefill \\[-.7em]


\noindent 5)\\
\indent (a) {\large$\int_{0}^{2}$}cx = 1 \indent $\Rightarrow$ \indent ({\Large $\frac{cx^2}{2}$})$\Big|_0^2$ \indent $\Rightarrow$\indent  0+2c = 1 \indent $\Rightarrow$\indent  c = 1/2\\

\indent (b) For $0 \leq x \leq 2$, $F_X(x)$ = {\large$\int_{}^{}$}cx = {\large$\int_{}^{}$}(1/2)x = {\Large $\frac{x^2}{4}$}\\
\indent \indent For other, $F_X(x)$ = 0\\


\indent\indent Thus, $F_X(x)$ = 
$
\begin{cases} 
	x^2/4 & 0 \leq x \leq 2 \\
	0 & otherwise 
\end{cases}
$\\\\

\indent (c) P($0.5 \leq X \leq 1.5$) = {\large$\int_{0.5}^{1.5}$}cx = ({\Large $\frac{x^2}{4}$})$\Big|_{0.5}^{1.5}$ = {\Large $\frac{1}{2}$}\\

\indent (d) P($1 \leq X \leq 2$) = $F_X(2) - F_X(1)$ = {\Large $\frac{2^2}{4}$} - {\Large $\frac{1^2}{4}$} = 1 - .25 = .75\\

\indent (e) .75 = $F_X(x)$ $\Rightarrow$ {\Large $\frac{x^2}{4}$} = .75 $\Rightarrow$ x = 1.732\\

\indent (f) E(X) =  {\large$\int_{0}^{2}$}x*f(x) $\Rightarrow$ {\large$\int_{0}^{2}$}{\Large $\frac{x^2}{2}$} $\Rightarrow$ ({\Large $\frac{x^3}{6}$})$\Big|_{0}^{2}$ $\Rightarrow$ {\Large $\frac{4}{3}$} = 1.333\\

\indent (g) Var(X) = {\large$\int_{0}^{2}$}(x - E(X))$^2$*f(x) $\Rightarrow$ {\large$\int_{0}^{2}$} (x - 1.333)$^2$*{\Large $\frac{x}{2}$} = {\Large $\frac{2}{9}$} = 0.2222\\


\noindent \hrulefill \\[-.7em]


\noindent 6)\\
\indent (a) For $0 \leq x \leq 1$, $F_X(x)$ = {\large$\int_{0}^{x}$}x = {\Large $\frac{x^2}{2}$}\\
\indent \indent For $1 < x \leq 1.5$, $F_X(x)$ = {\large$\int_{0}^{1}$}x + {\large$\int_{1}^{x}$}1 = ({\Large $\frac{x^2}{2}$})$\Big|_{0}^{1}$ + (x)$\Big|_{1}^{x}$ = {\Large $\frac{1}{2}$} + x - 1 = x - {\Large $\frac{1}{2}$}\\


\indent\indent Thus, $F_X(x)$ = 
$
\begin{cases} 
	x^2/2 & 0 \leq x \leq 1 \\
	x - 1/2 & 1 \leq x \leq 1.5 \\
	0 & otherwise 
\end{cases}
$\\\\

\indent (b) P($0.5 \leq X \leq 1.2$) = $F_X(1.2) - F_X(0.5)$ = (1.2 - 1/2) - (0.125) = 0.575\\

\indent (c) E(X) =  {\large$\int_{0}^{1}$}x*(x) + {\large$\int_{1}^{1.5}$}x*(1) = (1/3) + (5/8) = 0.958


\end{document}
















